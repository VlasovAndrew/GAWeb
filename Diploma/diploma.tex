\documentclass[bachelor, och, diploma, times]{SCWorks}
% параметр - тип обучения - одно из значений:
%    spec     - специальность
%    bachelor - бакалавриат (по умолчанию)
%    master   - магистратура
% параметр - форма обучения - одно из значений:
%    och   - очное (по умолчанию)
%    zaoch - заочное
% параметр - тип работы - одно из значений:
%    referat    - реферат
%    coursework - курсовая работа (по умолчанию)
%    diploma    - дипломная работа
%    pract      - отчет по практике
%    pract      - отчет о научно-исследовательской работе
%    autoref    - автореферат выпускной работы
%    assignment - задание на выпускную квалификационную работу
%    review     - отзыв руководителя
%    critique   - рецензия на выпускную работу
% параметр - включение шрифта
%    times    - включение шрифта Times New Roman (если установлен)
%               по умолчанию выключен
\usepackage[T2A]{fontenc}
\usepackage[cp1251]{inputenc}
\usepackage{graphicx}

\usepackage[sort,compress]{cite}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{fancyvrb}
\usepackage{longtable}
\usepackage{array}
\usepackage[english,russian]{babel}
\usepackage{pgfplots}
\usepackage{booktabs}
\usepackage{listings}
\usepackage{algorithm2e}

\usepackage[colorlinks=true]{hyperref}

\newcommand{\eqdef}{\stackrel {\rm def}{=}}

\newtheorem{lem}{Лемма}
\newcommand{\scale}{0.6}
\newcommand{\boxscale}{0.93}

\SetKwProg{Fn}{Function}{}{end}
\SetKwFunction{FnMutation}{Mutation}
\SetKwFunction{FnCrossover}{Crossover}
\SetKwFunction{FnSelection}{Selection}

\begin{document}

% Кафедра (в родительном падеже)
\chair{математической кибернетики и компьютерных наук}

% Тема работы
\title{Исследование параметров генетического алгоритма для поиска центральных вершин в графах}

% Курс
\course{4}

% Группа
\group{411}

% Факультет (в родительном падеже) (по умолчанию "факультета КНиИТ")
%\department{факультета КНиИТ}

% Специальность/направление код - наименование
\napravlenie{02.03.02 "--- Фундаментальная информатика и информационные технологии}
%\napravlenie{02.03.01 "--- Математическое обеспечение и администрирование информационных систем}
%\napravlenie{09.03.01 "--- Информатика и вычислительная техника}
%\napravlenie{09.03.04 "--- Программная инженерия}
%\napravlenie{10.05.01 "--- Компьютерная безопасность}

% Для студентки. Для работы студента следующая команда не нужна.
%\studenttitle{Студентки}

% Фамилия, имя, отчество в родительном падеже
\author{Власова Андрея Александровича}

% Заведующий кафедрой
\chtitle{к.\,ф.-м.\,н., доцент}
\chname{А.\,С.\,Иванов}

%Научный руководитель (для реферата преподаватель проверяющий работу)
\satitle{к.\,ф.-м.\,н.} %должность, степень, звание
\saname{С.\,В.\,Миронов}

% Год выполнения отчета
\date{2020}

\maketitle

% Включение нумерации рисунков, формул и таблиц по разделам
% (по умолчанию - нумерация сквозная)
% (допускается оба вида нумерации)
%\secNumbering

\tableofcontents

% Раздел "Обозначения и сокращения". Может отсутствовать в работе
%\abbreviations

% Раздел "Определения". Может отсутствовать в работе
%\definitions

% Раздел "Определения, обозначения и сокращения". Может отсутствовать в работе.
% Если присутствует, то заменяет собой разделы "Обозначения и сокращения" и "Определения"
%\defabbr


% Раздел "Введение"
\intro
Введение

\section{Описание задачи}
Для описания задачи сначала необходимо дать формальное определение понятию граф. 
Граф "--- это упорядоченная пара множеств $(V, E)$, где $V$ "--- множество вершин графа,
а $E$ "--- множество упорядоченных и неупорядоченных пар вершин "--- дуг или ребер. 
В случае, когда вершины в парах упорядочены, говорят, что граф является ориентированным, иначе "--- неориентированным.

В случает неориентированного графа также используется понятие связности графа "--- граф является связным, если между любой 
парой вершин существует по крайней мере один путь.
Кроме этого графы можно разделить на взвешенные или невзвешенные "--- в случае взвешенного графа каждое ребро имеет 
некоторый вес "--- положительное или отрицательное число, в случае невзвешенного графа каждое ребро имеет вес равный единице.

В данной работе предлагается и исследуется задача поиска центральных вершин в графах, поэтому далее приводится формальное 
описание задачи.
Для начала можно дать определение эксцентриситета вершины в графе. Эксцентриситетом $e$ вершины называется максимальное из 
расстояний от этой вершины до всех остальных вершин в графе.
С использованием этого определения можно сказать, что центральными вершинами в графе называются вершины с минимальным 
значением эксцентриситета, при чем само значение этого минимального эксцентриситета представляет собой радиус графа.

\section{Генетические алгоритмы}
Под генетическими алгоритмами принято 
подразумевать вероятностно"=эвристические алгоритмы, которые применяются для решения задач оптимизации.
Сфера применения генетических алгоритмов достаточно широка, с одной стороны данные алгоритмы могут быть применены
при решении задач оптимизации, в которых недостаточно накопленных математических и алгоритмических знаний ввиду уникальности 
задачи или ее мало изученности. Кроме этого генетические алгоритмы могут быть применены при решении задач, для которых не 
существует эффективных алгоритмов решения "--- задачи из NP"=класса, а также подобные алгоритмы могут найти применение при 
попытках уменьшить временные затраты на решение хорошо изученной задачи.

В основе любого генетического 
алгоритма лежит моделирование 
эволюционного развития живых 
организмов за счет таких факторов, 
как естественный отбор, мутации и 
скрещивание.
Процесс скрещивания или кроссинговера 
впервые начал изучался в XIX веке 
ученым"=ботаником Г. Менделем.
В результате его исследований было 
установлено, что в набор генов живых 
организмов передаются гены его 
родителей причем в скомбинированном 
виде. Этот факт во многом объясняет с 
одной стороны все многообразие живых 
существ, а с другой явление передачи 
полезных свойств через поколения.

В дальнейшем с развитием науки были 
сделаны ряд открытий, связанных с 
таким явлением, как мутация генов.
Под мутацией понимается изменение 
генетических участков организма.
Чаще всего эти изменения происходят 
под воздействием внешних факторов или 
внутренних. Такие мутации чаще всего 
приводят к негативным последствиям, 
но вместе с там у живого организма 
появляется небольшая возможность 
получить новые внешние свойства, 
которые будут выгодно выделять его 
среди других организмов и переведут 
на новый виток эволюции.

Вместе с тем элементом, который 
отвечает за селекцию и определение 
какие особи являются наиболее 
приспособленными к окружающей 
действительности, выступает 
естественный отбор. Отмеченный в работах Ч. Дарвина как один из ключевых процессов, который обеспечивает эволюционное 
развитие, естественный отбор сохраняет организмы с наиболее высоким уровнем приспособленности к окружающей среде и удаляет
особи из низким уровнем приспособленности.

При рассмотрении природы, которая окружает организм, как некоторой сложно организованной системы легко заметить, что 
в процессе эволюции популяции живые существа под воздействием описанных факторов способны с легкостью решать некоторую 
оптимизационную задачу, находя в окружающих условиях оптимальные положения и состояния. В связи с этим была предложена идея 
генетических алгоритмов "--- смоделировать описанные три процесса и на их основе запустить оптимизационный поиск.
Главный толчок для развития генетических алгоритмов был дан в работе Дж. Г. Холланда \cite{HOLLAND}.

Каждый генетический алгоритм представляет собой итерационное применение операторов мутации, скрещивания и естественного 
отбора. При этом все эти операторы применяются к основной единице эволюции "--- популяции. В ходе такого итерационного 
применения этих операторов популяция должна найти некоторое оптимальное решение, при этом отнюдь не гарантируется, что это 
решение будет верным или же найденный оптимум будет являться глобальным. 

\subsection{Представление решения и начальная популяция}
Первым этапом в реализации генетического алгоритма является выбор способа кодирования решения. 
Закодированные возможные решения будут представлять собой особи в популяции.
Способ должен быть выбран таким образом, чтобы у операторов мутации и скрещивания была возможность с легкостью изменять 
каждую особь. Чаще всего при поиске оптимума некоторой вещественной функции каждая особь "--- это набор битов, которые 
кодируют вещественное число. Но данный подход не всегда может быть применен, поэтому способ кодирования решения выбирается 
чаще всего из постановки решаемой задачи.
Одним из параметров генетического алгоритма является размер популяции $N$.

\subsection{Оператор скрещивания}
Данный оператор занимается выбором особей для скрещивания и самим процессом скрещивания.
Задача этого оператора скомбинировать гены двух особей и создать на их основе новую особь для перехода в следующее поколение.
При этом с этим процесс скрещивания происходит не всегда, а с вероятностью заданной в виде параметра $p_c$.

\subsection{Оператор мутации}
Оператор просматривает каждую особь в популяции и некоторым образом ее изменяет, при этом работает так же с некоторой 
вероятностью заданной через параметр $p_m$.

\subsection{Оператор естественного отбора}
При естественном отборе важна функция для оценки приспособленности каждой особи в популяции.
Чаще всего в качестве такой функции выступает функция, оптимальное значение которой ищется. 
Для начала оператор вычисляет приспособленность каждого организма в популяции после чего формируется для каждой особи 
вероятность ее попадания в следующее поколение. Эта вероятность выше, чем  наиболее оптимальное решение 
представляет собой рассматриваемый элемент.
Выбор элементов популяции осуществляется при помощи так называемого колеса рулетки "--- каждой особи ставится в соответствие 
сектор в зависимости от уровня вероятности, после чего происходит генерация псевдослучайного числа, и в зависимости от того 
в какой сектор попало число, тот элемент и переходит в следующее поколение. Очевидно, что в результате окажется большинство 
особей с высоким уровнем приспособленности.

Среди недостатков, которыми обладает данный подход, можно выделить неуниверсальность генетических алгоритмов. Каждая задача 
требует уникальной разработки и адаптации всех описанных этапов под решаемую задачу. Кроме этого успешность работы алгоритма 
зависит от значений параметров $p_c$, $p_m$ и $N$.

Таким образом основными вопросами, которые стоят перед разработчиком, является реализация процессов скрещивания, мутации, 
естественного отбора и выбор критерия остановки алгоритма. Кроме этого необходимо исследовать параметры $p_c$, $p_m$ и $N$, 
которые существенным образом влияют на работу генетического алгоритма. 

\section{Алгоритмы для поиска центральных вершин}
Так как генетические алгоритмы являются методом решения оптимизационных задач, в задаче поиска центральных вершин необходимо 
выделить функцию, оптимальное значение которой требуется оптимизировать.
Легко заметить, что если рассмотреть граф $G = (V, E)$ и функцию на нем $F: V \mapsto \mathbb{R}$, которая определяет 
эксцентриситет каждой вершины, то получается, что для нахождения центральных вершин необходимо найти минимальное значение 
этой функции с помощью генетического алгоритма. 

При этом следует отметить, что для поиска центральных вершин существует ряд точных алгоритмов, гарантирующих верное решение 
во всех случаях. 

\subsection{Тривиальный алгоритм}
Легко заметить, что задача поиска центральных вершин может быть с легкостью решена при 
использовании алгоритма обхода в ширину. Для того, чтобы найти вершину с минимальным эксцентриситетом
необходимо запустить обход в ширину из каждой вершины графа, после чего станут известны все длины путей между всеми вершинами
в графе. Алгоритм поиска в ширину имеет ассимптотическое время работы равное $O(n + m)$ \cite{CORMEN}.
При этом, если запустить его из каждой вершины, то время работы всего алгоритма будет равным $O(n^2 + nm)$.

\subsection{Алгоритмы с улучшенной ассимптотикой}
Кроме этого данная задача была хорошо изучена различными исследователями [ссылки], которые 
предлагали несколько подходов, 
для решения подобных задач.
Например, в работе \cite{Aingworth} предлагается алгоритм, использующий эвристику разделения вершин на два множества "--- множество 
вершин с высокой степенью и множество вершин с низкой степенью. После такого разделения для множества с вершинами с высокой 
степенью строится доминирующее множество, после чего из этого множества запускаются обходы в ширину.
Кроме этого алгоритм поиска в ширину запускается внутри множества вершин с низкой степенью. Алгоритм обхода проходит не по всем вершинам в графе, а лишь по вершинам внутри множеств, что позволяет быстрее найти центральные вершины, а кроме этого радиус графа.

\subsection{Алгоритмы, использующие матричное умножение}
В работе \cite{Seidel} приводится алгоритм, который использует в своей основе матричное представление графов.
Данный алгоритм оперирует в своей 
работе матрицами и самыми ресурсоемкими задачами в этом алгоритме являются процессы матричного перемножения, поэтому целиком и полностью ассимптотика этого подхода равна времени выполнения матричного умножения. Тривиальный алгоритм имеет ассимптотику $O(n^3)$, но при этом существует алгоритм быстрого матричного умножения \cite{Strassen1969}, способный решить 
эту задачу за время $O(n^{2.81})$.



\section{Описание разработанного генетического алгоритма}
Генетический алгоритм должен содержать адаптированные под решаемую задачу этапы 
скрещивания, мутации и естественного отбора.
Основная идея алгоритма может быть выражена следующим образом. 
Пусть существует некоторое абстрактное или реальное изображение графа,
причем в центре этого изображения находятся центральные вершины графа.
Тогда, если популяция генетического алгоритма представляет собой 
набор вершин, то этот набор может быть представлен в виде некоторого шара, внутри которого 
находится центральные вершины графа (см. рисунок \ref{pic1}).
\begin{figure}[!ht]
\centering
\includegraphics[scale = \scale]{pic/graph/pic1.png} 
\caption{\label{pic1} Начальное состояние алгоритма (желтый цвет "--- центральная вершина, зеленый цвет "--- начальная 
популяция)}
\end{figure}

Из этой идеи следует, что для того чтобы найти центральные вершины необходимо, чтобы эта абстрактная сфера сжималась к 
центру. Именно этот смысл заложен в работу оператора скрещивания. В добавок к этому алгоритм должен сжимать эту <<сферу>> к 
глобальному центру, не сбиваясь в локальные оптимальные значение, за это отвечает оператор мутации. Естественный отбор 
соответственно занимается выбором вершин с оптимальными эксцентриситетами. Если реализовать все эти три шага и запустить их, 
то в идеальном варианте после нескольких итераций популяция алгоритма должна находиться в состоянии, которое показано на 
рисунке \ref{pic2}.
\begin{figure}[!ht]
\centering
\includegraphics[scale = \scale]{pic/graph/pic2.png} 
\caption{\label{pic2} Состояние алгоритма после нескольких итераций (желтый цвет "--- центральная вершина, зеленый цвет "--- 
начальная популяция)}
\end{figure}

\subsection{Старт алгоритма}
Для начала алгоритма необходимо сгенерировать начальную популяцию с размером $N$, которая и будет эволюционировать.
В предлагаемом алгоритме в качестве начальной популяции генерируется случайный набор уникальных вершин, причем вероятность 
попадания в начальную популяцию одинакова для всех вершин.

\subsection{Естественный отбор}
Как уже говорилось ранее естественный отбор занимается выбором оптимальных вершин для продолжения работы алгоритма.
Для каждой вершины находится ее эксцентриситет при помощи обхода в ширину (см. рисунок \ref{pic3}), после чего методом колеса рулетки, при этом приоритет отдается вершинам с меньшим эксцентриситетом.
\begin{figure}[!ht]
\centering
\includegraphics[scale = \scale]{pic/graph/pic5.png} 
\caption{\label{pic3} Процесс поиска самой удаленной вершины (желтый цвет "--- центральная вершина, зеленый цвет "--- начальная популяция, красный "--- 
вершины на пути в самые удаленные точки графа)}
\end{figure}

\subsection{Этап скрещивания}
Основной смысл разработанного алгоритма кроется в операторе скрещивания. Так как необходимо, чтобы <<сфера>> описываемая 
популяцией с каждой итерацией сжималась, то скрещивание реализовано следующим образом: в качестве родителей выбираются две 
вершины из популяции, после чего между ними находится кротчайший путь, после чего из этого пути выбирается одна вершина в качестве потомка (см. рисунок \ref{pic4}). Именно такая реализация данного этапа позволяет алгоритму сходиться к центральным вершинам. При этом процесс скрещивания происходит с вероятностью $p_c$.
\begin{figure}[!ht]
\centering
\includegraphics[scale = \scale]{pic/graph/pic3.png} 
\caption{\label{pic4} Процесс скрещивания (желтый цвет "--- центральная вершина, зеленый цвет "--- начальная популяция, красный "--- кротчайший путь между 
вершинами популяции)}
\end{figure}

\subsection{Этап мутации}
Для того, чтобы у алгоритма была возможность выхода из локальных оптимальных значений существует этап мутации, который имеет 
следующую реализацию: перебираются все вершины в популяции и для каждой вершины находятся ее соседи "--- вершины смежные с ней, после чего с вероятностью $p_m$ вершина заменяется на одного из своих соседей (см. рисунок \ref{pic5})
\begin{figure}[!ht]
\centering
\includegraphics[scale = \scale]{pic/graph/pic4.png} 
\caption{\label{pic5} Процесс мутации (желтый цвет "--- центральная вершина, зеленый цвет "--- начальная популяция, красный "--- соседние вершины одной из 
вершин в популяции)}
\end{figure}

Все описанные этапы представлены в виде псевдокода \ref{alg-1}.

	\begin{algorithm} 
	\Begin{
		\KwData{Graph $G$}
		\KwResult{Vertex $c$, which is center of graph $G$}
		\For{ $i := 1 $ \KwTo $populationSize$ } {
			$population[i]  \leftarrow random\ vertex\ \in G$;  \\
		}
			
		\For{$i \leftarrow 1$ \KwTo $iterationNumber$} {
			$Crossover()$ \\
			$Mutation()$ \\
			$Selection()$ \\
		}
		$c.eccentricity \leftarrow \infty$ \\
		\For{$v \in population$}{
			\If{$v.eccentricity < c.eccentricity$}{
				$c \leftarrow v$ \\
			}
		}
	}
	
	\Fn{\FnMutation{}} {
		\KwData{Population on current algorithm step}
		\KwResult{Population after applying a mutation operator to each individual}
		\For{$i \leftarrow 1$ \KwTo $populationSize$} {
			\If{$randomValue < mutationProbability$} {
					$neighbours \leftarrow popilation[i].getNeighbours$ \\
					$population[i] \leftarrow random\ vertex\ from\ neighbours$ \\
			}
		}	
	}
	
	\Fn{\FnCrossover{}} {
		\KwData{Population on current algorithm step}
		\KwResult{Population after crossover}
		\For{$i \leftarrow 1$ \KwTo $populationSize$} {
			\If{$randomValue < crossPopulation$}{
					$u \leftarrow random\ vertex\ from\ popualtion$ \\
					$v \leftarrow random\ vertex\ from\ population$ \\
					$path \leftarrow G.pathBetween(u, v)$ \\
			}	
		}		
	}
	
	\Fn{\FnSelection{}} {
		\KwData{Population on current algorithm step}
		\KwResult{Population for next algorithm step}
		\For{$i \leftarrow 1$ \KwTo $populationSize$} {
			$eccentricity[i] \leftarrow population[i].eccentricity$ \\
		}
		\For{$i \leftarrow 1$ \KwTo $populationSize$} {
			$probability[i] \leftarrow number\ from\ [0, 1] $
		}
		
		\For{$i \leftarrow 1$ \KwTo $populationNumber$}{
			$nextPopulation[i] \leftarrow v\ from\ population\ with\ using\ probability$
		}
	}
	\caption{\label{alg-1} Псевдокод основных этапов предлагаемого алгоритма}
	\end{algorithm}	


При работе каждого из этапов в оперативной памяти поддерживается матрица $n \times n$, где $n$ "--- число вершин в графе, 
хранящая найденные расстояния между вершинами, а кроме этого такая же матрица, внутри которой лежат кротчайшие пути между 
вершинами. Такое поддержание матриц позволяет многократно не пересчитывать расстояния между вершинами, если этого требует 
алгоритм. 
Визуальную работу алгоритма можно увидеть на рисунке \ref{pic6}.

\begin{figure}[!ht]
	\begin{minipage}{0.5\linewidth}
		\includegraphics[width = \linewidth]{pic/steps/step1.png} \center{Начальная популяция} \\	
	\end{minipage}
	\hfill
	\begin{minipage}{0.5\linewidth}
		\includegraphics[width = \linewidth]{pic/steps/step3.png} \center{Популяция после двух шагов} \\
	\end{minipage}
	\vfill
	\begin{minipage}{0.5\linewidth}
		\includegraphics[width = \linewidth]{pic/steps/step5.png} \center{Популяция после четырех шагов} \\
	\end{minipage}
	\hfill
	\begin{minipage}{0.5\linewidth}
		\includegraphics[width = \linewidth]{pic/steps/step7.png} \center{Популяция после шести шагов} \\
	\end{minipage}
	\vfill
	\begin{minipage}{0.5\linewidth}
		\includegraphics[width = \linewidth]{pic/steps/step9.png} \center{Популяция после восьми шагов} \\
	\end{minipage}
	\hfill
	\begin{minipage}{0.5\linewidth}
		\includegraphics[width = \linewidth]{pic/steps/step11.png} \center{Популяция после десяти шагов} \\
	\end{minipage}
	\caption{\label{pic7} Шаги работы алгоритма (желтый цвет "--- центральная вершина, красный "--- популяция, темно синий "--- особь, представляющая правильный ответ)}
\end{figure}

\section{Реализация алгоритма}
В качестве языка программирования для имплементации алгоритма был выбран язык программирования C++.
Кроме этого в качестве среды разработки, в которой производилась реализация алгоритма, была выбрана 
\verb|Visual Studio 2017|, а вычислительная машина, на которой были выполнены все испытания обладает оперативной памятью с 
размером \verb|6.0 GB| и процессором \verb|AMD A8-7410| с частотой \verb|2.20 GHz|.

Кроме этого для запусков тестов алгоритма необходимы наборы графов с разными свойствами. Для создания графов использовалась 
\verb|Python| библиотека \verb|NetworkX|, которая предоставляет возможности для генерации графов на основе различных моделей 
случайных графов.

\section{Модели случайных графов}
Для исследования алгоритма применялись следующие модели случайных графов: модель Эрдеша"=Реньи, модель Барабаши"=Альберт и 
модель случайного геометрического графа. Все они в той или иной степени частично описывают реальные графы, такие как 
компьютерные или социальные сети.

\subsection{Модель случайного графа Эрдеша"=Реньи}
Данная модель представленная в работе \cite{ER} является одной из самых простых и базовых моделей случайного графа. Изначально для создания графа задаются 
два параметра $n$ "--- число вершин в графе и $p$ "--- вероятность проведения ребра. 
Далее для построения графа рассматриваются все пары вершин, и между ними проводится неориентированное ребро с вероятностью $p$. В данной модели ввиду ее 
простоты формулировки довольно легко выводятся формулы, зависящие от параметра $p$ и $n$, которые описывают основные характеристики графов, такие как 
связность, размер максимальной клики, распределение степени вершин и т.д. Поэтому если удается установить, что граф в рассматриваемой задаче близок по 
свойствам с графом Эрдеша"=Реньи, то можно без труда получить много информации об изучаемом графе.

\subsection{Модель случайного графа Барабаши"=Альберт}
Данная модель случайного графа была предложена в работе \cite{BA}. На данный момент описанная модель позволяет создавать так называемые безмасштабные сети 
"--- графы, в которых распределение степеней подчиняется степенному закону. Исследования данного подхода показали, что графовые модели, которые описывают 
взаимосвязи внутри различных самоорганизующихся систем, совпадают с моделью Барабаши"=Альберта. К таким сетям относятся ряд графов социальных сетей, сеть 
Интернет, ряд графовых моделей в природных сетях. 

В ходе построения случайного графа поддерживаются два основных принципа, которые главным образом характеризуют безмасштабные сети. Первый из них принцип расширения сети, второй "--- предпочтительное прикрепление. Первый принцип описывается тем фактом, что в существующую сеть могут постоянно добавляться новые узлы, при этом не нарушая его свойств из"=за второго принципа. Принцип предпочтительного прикрепления заключается в том, что добавляемый узел случайным образом прикрепляется ребрами к вершинам, которые уже существуют в графе, при этом предпочтение отдается вершинам с большей степенью, формально вероятность проведения ребра к $i$"=му узлу описывается следующий формулой:
\[
	p_i = \frac{k_i}{\sum_j k_j},
\] 
где $k$ "--- степень узла, $j$ пробегает все вершины в графе. 

Для создания графа задаются два параметра $n$ "--- число вершин в создаваемом графе, и $m$ "--- число ребер, которые проводится из каждой новой добавляемой вершины в граф. Алгоритм создания достаточно прост, в качестве начального графа берется связный граф с числом вершин большим или равным $m$, после чего добавляются новые вершины до необходимого количества, при этом каждая новая вершина соединяется с $m$ вершинами случайным образом с вероятностным распределением, описанным формулой выше.

\subsection{Геометрический случайный граф}
Данная модель случайного графа \cite{GEOM} описывает основные свойства, которые возникают в графовых моделях компьютерных сетей и сетей, имеющих явную географическую интерпретацию. Для построения графа выбирается размерность пространства, в котором будет создаваться граф, наиболее часто выбирается двумерное пространство, на котором случайным образом генерируется набор геометрических точек равных по количеству числу узлов в создаваемом графе, после чего для каждой пары точек рассчитывается евклидово расстояние между ними и проводится ребро в том случае, если расстояние меньше параметра $r$, который задается заранее.

Данная модель случайного графа имеет свои отличительные характеристики, которые не совпадают с моделями Эрдеша"=Реньи и Барабаши"=Альберта.

\section{Результаты вычислительных экспериментов}
Для выявления сильных и слабых сторон предложенного алгоритма его сравнение проводилось с рядом точных алгоритмов, а также с алгоритмом <<N4N>>. В качестве тестовых графов были выбраны графовые модели описанные ранее. Для модели Эрдеша"=Реньи в качестве параметра $p$ было выбрано значение 5\%, для модели Барабаши"=Альберта $m = 2$, а для геометрического случайного графа $r = 0.1$. 

Для сравнения по временным результатам были реализованы тривиальный алгоритм и алгоритм с улучшенной асимптотикой. Эти алгоритмы и описанный в данной работе запускались на трех моделях случайных графов, с количеством вершин 500, 1000, 1500, 2000, 2500, 5000. Исходя из практических экспериментов в качестве размера популяции выбрано значение 50, для оператора скрещивания 0.7, для оператора мутации 0.1, кроме этого число итераций ограничено числом 20. Результаты временных измерений приведены на графиках \ref{pic6}. Из полученных результатов видно, что созданный генетический алгоритм дает выигрыш по времени в несколько раз по сравнению с точными алгоритмами. 

\begin{figure}
	\scalebox{\boxscale}{
	\begin{minipage}{0.5\linewidth}
				\centering
				\begin{tikzpicture}
				\begin{axis}[
						legend pos = north west,
						height = \linewidth, 
						width = \linewidth,
						xmin = 500, xmax = 5000,
						ylabel = {Время, сек.},
						xlabel = {Количество вершин},
					]
				\addplot  coordinates {
					(500, 0.302)
					(1000, 1.112)
					(1500, 2.223)
					(2000, 4.518)
					(2500, 8.702)
					(5000, 65.393)
				};
				\addplot  coordinates {
					(500,  0.37)
					(1000, 0.87)
					(1500, 1.25)
					(2000, 1.99)
					(2500, 3.22)
					(5000, 13.64)
				};
				\addplot  coordinates {
					(500, 0.16)
					(1000, 0.60)
					(1500, 1.44)
					(2000, 2.17)
					(2500, 2.68)
					(5000, 8.47)
				};
				\end{axis}
				\end{tikzpicture}
				(\textit{a})
			\end{minipage}
		}
		\hfill
		\scalebox{\boxscale}{
		\begin{minipage}{0.5\linewidth}
			\centering
			\begin{tikzpicture}
				\begin{axis}[
						legend pos = north west,
						height = \linewidth, 
						width = \linewidth,
						xmin = 500, xmax = 5000,
						ylabel = {Время, сек.},
						xlabel = {Количество вершин}
					]
				\addplot  coordinates {
					(500, 0.377)
					(1000, 1.272)
					(1500, 3.392)
					(2000, 6.43)
					(2500, 14.406)
					(5000, 93.67)
				};
				\addplot  coordinates {
					(500, 0.072)
					(1000, 0.564)
					(1500, 1.1328)
					(2000, 1.70)
					(2500, 3.204)
					(5000, 18.456)
				};
				\addplot  coordinates {
					(500, 0.11)
					(1000, 0.38)
					(1500, 0.54)
					(2000, 1.022)
					(2500, 1.64)
					(5000, 4.19)
				};
				\end{axis}
		\end{tikzpicture}
				(\textit{b})
		\end{minipage}
		}
		\vfill
		\scalebox{\boxscale}{
			\begin{minipage}{0.5\linewidth}
					\centering
					\begin{tikzpicture}
					\begin{axis}[
							legend pos = north west,
							height = \linewidth, 
							width = \linewidth,
							xmin = 500, xmax = 5000,
							ylabel = {Время, сек.},
							xlabel = {Количество вершин}
					]
					\addplot  coordinates {
						(500, 0.377)
						(1000, 1.272)
						(1500, 3.392)
						(2000, 6.43)
						(2500, 14.40)
						(5000, 93.67)
					};
					\addplot  coordinates {
						(500, 0.072)
						(1000, 0.564)
						(1500, 1.1328)
						(2000, 1.70)
						(2500, 3.204)
						(5000, 18.456)
					};
					\addplot  coordinates {
						(500, 0.11)
						(1000, 0.38)
						(1500, 0.54)
						(2000, 1.022)
						(2500, 1.64)
						(5000, 4.19)
					};
					\end{axis}
					\end{tikzpicture}
					(\textit{c})
	 		\end{minipage}
 		}
	\caption{\label{pic6} Графики зависимости времени работы от размеров графа (синий цвет "--- тривиальный $O(nm + n^2)$ алгоритм, красный "--- 	алгоритм с улучшенной асимптотикой $O(m\sqrt{n})$, коричневый "--- генетический алгоритм): (\textit{a}) "--- модель Эрдеша"=Реньи $p = 1\%$, (\textit{b}) "--- модель Барабаши"=Альберта $m = 2$, (\textit{c}) "--- геометрический случайный граф $r = 0.1$}
\end{figure}

Также так как эвристический алгоритм не гарантирует получение точного ответа, а допускает некий процент ошибки, то для изучения точности алгоритма были 
проведены тесты позволяющие выявить процент неправильных ответов. Для этого алгоритм запускался на все тех же графах, при этом так как размерности графа, 
позволяют за приемлемые временные затраты с помощью точного алгоритма найти центральные вершины, то зная эту информацию можно говорить о проценте 
неправильных ответов. Для сравнения брался алгоритм <<N4N>>, после чего оба алгоритма запускались 100 раз, что позволило подсчитать процент ошибки. 
Результаты вычислительных экспериментов приведены в таблицах \ref{tab1}, \ref{tab2} и \ref{tab3}. 

\begin{table}[!ht]
\centering
\small
\caption{\label{tab1} Время работы и процент ошибки алгоритмов на случайных геометрических графах}
\begin{tabular}{@{}ccccccc@{}}
\toprule
№                      & \multicolumn{2}{c}{Размер графа}       & \multicolumn{2}{c}{Время, сек.}    & \multicolumn{2}{c}{Ошибка, \%} \\ \midrule
                       & N     & M                            & Созданный алг.   & N4N алг.                    & Созданный алг.           & N4N алг.          \\ \midrule
\multicolumn{1}{c|}{1} & 500   & \multicolumn{1}{c|}{3572}    & 0.11  & \multicolumn{1}{c|}{0.39} & 38.0          & 40.0           \\
\multicolumn{1}{c|}{2} & 1000  & \multicolumn{1}{c|}{14202}   & 0.31  & \multicolumn{1}{c|}{0.77} & 21.0          & 50.0           \\
\multicolumn{1}{c|}{3} & 1500  & \multicolumn{1}{c|}{31861}   & 0.71  & \multicolumn{1}{c|}{1.44} & 13.0          & 62.0           \\
\multicolumn{1}{c|}{4} & 2000  & \multicolumn{1}{c|}{57438}   & 1.20  & \multicolumn{1}{c|}{1.92} & 8.0           & 48.0           \\
\multicolumn{1}{c|}{5} & 2500  & \multicolumn{1}{c|}{90268}   & 1.76  & \multicolumn{1}{c|}{2.68} & 4.0           & 30.0           \\
\multicolumn{1}{c|}{6} & 5000  & \multicolumn{1}{c|}{358553}  & 4.48  & \multicolumn{1}{c|}{8.61} & 0.0           & 0.0            \\
\multicolumn{1}{c|}{7} & 10000 & \multicolumn{1}{c|}{1439255} & 13.54 & \multicolumn{1}{c|}{26.0} & 0.0           & 0.0            \\ \bottomrule
\end{tabular}
\end{table}

\begin{table}[!ht]
\centering
\small
\caption{\label{tab2} Время работы и процент ошибки алгоритмов на модели случайного графа Барабаши"=Альберта}
\begin{tabular}{@{}ccccccc@{}}
\toprule
                      & \multicolumn{2}{c}{Размеры графа}     & \multicolumn{2}{c}{Время, сек.}   & \multicolumn{2}{c}{Ошибка, \%} \\ \midrule
                       & N     & M                          & Созданный алг. & N4N алг.                       & Созданный алг.            & N4N алг.          \\ \midrule
\multicolumn{1}{c|}{1} & 500   & \multicolumn{1}{c|}{996}   & 0.07 & \multicolumn{1}{c|}{0.29} & 16.0           & 0.0          \\
\multicolumn{1}{c|}{2} & 1000  & \multicolumn{1}{c|}{1996}  & 0.18 & \multicolumn{1}{c|}{0.68} & 12.0           & 0.0          \\
\multicolumn{1}{c|}{3} & 1500  & \multicolumn{1}{c|}{2996}  & 0.37 & \multicolumn{1}{c|}{1.24} & 4.0            & 0.0          \\
\multicolumn{1}{c|}{4} & 2000  & \multicolumn{1}{c|}{3996}  & 0.55 & \multicolumn{1}{c|}{1.67} & 1.0            & 0.0          \\
\multicolumn{1}{c|}{5} & 2500  & \multicolumn{1}{c|}{4996}  & 0.69 & \multicolumn{1}{c|}{2.18} & 0.0            & 0.0          \\
\multicolumn{1}{c|}{6} & 5000  & \multicolumn{1}{c|}{9996}  & 1.84 & \multicolumn{1}{c|}{8.28} & 0.0            & 0.0          \\
\multicolumn{1}{c|}{7} & 10000 & \multicolumn{1}{c|}{19996} & 3.90 & \multicolumn{1}{c|}{15.8} & 0.0            & 0.0          \\ \bottomrule
\end{tabular}
\end{table}



\begin{table}[!ht]
\centering
\small
\caption{\label{tab3} Время работы и процент ошибки алгоритмов на модели случайного графа Эрдеша"=Реньи}
\begin{tabular}{ccccccc}
\hline
\multicolumn{1}{l}{}   & \multicolumn{2}{c}{Размеры графа}   & \multicolumn{2}{c}{Время, сек.}            & \multicolumn{2}{c}{Ошибка, \%} \\ \hline
\multicolumn{1}{l}{}   & N     & M                           & Созданный алг. & N4N алг.                  & Созданный алг.    & N4N алг.   \\ \hline
\multicolumn{1}{c|}{1} & 500   & \multicolumn{1}{c|}{1288}   & 0.16           & \multicolumn{1}{c|}{0.44} & 29.0              & 43.0       \\
\multicolumn{1}{c|}{2} & 1000  & \multicolumn{1}{c|}{4905}   & 0.60           & \multicolumn{1}{c|}{1.30} & 0.0               & 0.0        \\
\multicolumn{1}{c|}{3} & 1500  & \multicolumn{1}{c|}{11153}  & 1.44           & \multicolumn{1}{c|}{1.90} & 0.0               & 0.0        \\
\multicolumn{1}{c|}{4} & 2000  & \multicolumn{1}{c|}{20201}  & 2.17           & \multicolumn{1}{c|}{2.79} & 0.0               & 0.0        \\
\multicolumn{1}{c|}{5} & 2500  & \multicolumn{1}{c|}{31187}  & 2.68           & \multicolumn{1}{c|}{2.94} & 0.0               & 0.0        \\
\multicolumn{1}{c|}{6} & 5000  & \multicolumn{1}{c|}{124658} & 8.47           & \multicolumn{1}{c|}{11.0} & 0.0               & 0.0        \\
\multicolumn{1}{c|}{7} & 10000 & \multicolumn{1}{c|}{500471} & 25.4           & \multicolumn{1}{c|}{39.3} & 0.0               & 0.0        \\ \hline
\end{tabular}
\end{table}

Из полученных результатов видно, что созданный алгоритм не уступает существующему эвристическому алгоритму. Предложенный алгоритм превосходит второй 
генетический алгоритм в несколько раз. Это во многом объясняется тем, что в алгоритме <<N4N>> используется множество для описания одной особи в популяции, 
а также при процессе мутации для вершин, которые претендуют на изменение особи, находится эксцентриситет, всех этих процессов нет в созданном алгоритме, 
поэтому его время работы меньше.
При этом видно, что алгоритм <<N4N>> на некоторых моделях случайных графов имеет меньший процент ошибки по сравнению с предложенным алгоритмом, однако 
этот процент нивелируется с увеличением размерности графа.

\section{Исследование параметров генетического алгоритма}
В приведенных ранее результатах в качестве значений параметров генетического алгоритма были выбраны значения $N = 50$, $p_c 
= 0.7$ и $p_m = 0.1$. Однако эти значения выбирались в качестве тестовых для того, чтобы проверить жизнеспособность идей, 
заложенных в алгоритм.
При этом эти параметры ключевым образом влияют как на точность алгоритма, так и на время его выполнения.
В связи с этим был также проведен еще ряд экспериментов, в которых исследовались эти параметры.
Для начала были произведены запуски, в которых перебирались значения для $p_m$ и $p_c$ от 0 до 1. Для каждого значения этих параметров измерялось время работы алгоритма и его процент ошибок. При этом значение размера популяции было равно 20. 
Результаты этих экспериментов представлены в таблицах \ref{tab4} и \ref{tab5}.

\begin{table}[!ht]
\small
\centering
\caption{Время работы (сек.) алгоритма  на представителе модели геометрического случайного графа $|V| = 
2500$, $|E| = 90268$, $N = 20$} \label{tab4}
\begin{tabular}{llllllllllll}
pm/pc & 0.0  & 0.1  & 0.2  & 0.3  & 0.4  & 0.5  & 0.6  & 0.7  & 0.8  & 0.9  & 1.0  \\
0.0   & 0.06 & 0.11 & 0.13 & 0.15 & 0.17 & 0.19 & 0.20 & 0.29 & 0.28 & 0.27 & 0.31 \\
0.1   & 0.18 & 0.26 & 0.27 & 0.33 & 0.32 & 0.36 & 0.36 & 0.41 & 0.40 & 0.40 & 0.40 \\
0.2   & 0.29 & 0.35 & 0.52 & 0.55 & 0.52 & 0.54 & 0.49 & 0.54 & 0.56 & 0.54 & 0.50 \\
0.3   & 0.45 & 0.50 & 0.53 & 0.57 & 0.60 & 0.54 & 0.60 & 0.58 & 0.65 & 0.68 & 0.66 \\
0.4   & 0.51 & 0.53 & 0.64 & 0.71 & 0.69 & 0.62 & 0.64 & 0.66 & 0.70 & 0.75 & 0.78 \\
0.5   & 0.62 & 0.67 & 0.74 & 0.79 & 0.78 & 0.84 & 0.87 & 0.82 & 0.80 & 0.82 & 0.93 \\
0.6   & 0.60 & 0.77 & 0.77 & 0.96 & 0.87 & 0.86 & 0.88 & 0.93 & 1.01 & 1.04 & 1.14 \\
0.7   & 0.86 & 0.96 & 1.04 & 1.09 & 1.13 & 1.09 & 1.00 & 1.15 & 1.03 & 1.32 & 1.00 \\
0.8   & 0.76 & 0.85 & 0.89 & 0.93 & 0.98 & 0.96 & 1.02 & 1.19 & 1.05 & 1.08 & 1.13 \\
0.9   & 0.82 & 0.91 & 1.01 & 1.01 & 1.23 & 1.29 & 1.30 & 1.31 & 1.18 & 1.20 & 1.10 \\
1.0   & 0.96 & 1.08 & 1.03 & 1.22 & 1.25 & 1.30 & 1.30 & 1.26 & 1.18 & 1.32 & 1.50\\
\end{tabular}
\end{table}

\begin{table}[!ht]
\small
\centering
\caption{Процент ошибок (\%) алгоритма  на представителе модели геометрического случайного графа $|V|$ = 2500 $|E|$ = 90268 N = 20 } \label{tab5}
\begin{tabular}{llllllllllll}
pm/pc & 0.0  & 0.1  & 0.2  & 0.3  & 0.4  & 0.5  & 0.6  & 0.7  & 0.8  & 0.9  & 1.0  \\
0.0   & 81 & 54 & 32 & 52 & 42 & 52 & 59 & 53 & 62 & 60 & 61 \\
0.1   & 48 & 35 & 19 & 28 & 33 & 34 & 28 & 32 & 23 & 39 & 31 \\
0.2   & 46 & 27 & 29 & 20 & 21 & 25 & 21 & 25 & 26 & 21 & 17 \\
0.3   & 44 & 23 & 18 & 17 & 20 & 18 & 15 & 14 & 15 & 17 & 21 \\
0.4   & 32 & 28 & 19 & 22 & 9 & 16 & 21 & 16 & 18 & 30 & 16 \\
0.5   & 32 & 16 & 14 & 19 & 20 & 16 & 22 & 18 & 14 & 14 & 9 \\
0.6   & 30 & 18 & 12 & 21 & 11 & 12 & 15 & 9 & 12 & 20 & 18 \\
0.7   & 32 & 17 & 20 & 14 & 13 & 10 & 19 & 12 & 22 & 8 & 12 \\
0.8   & 33 & 22 & 20 & 14 & 21 & 15 & 21 & 16 & 15 & 14 & 19 \\
0.9   & 24 & 18 & 24 & 15 & 23 & 17 & 19 & 14 & 20 & 11 & 14 \\
1.0   & 32 & 16 & 13 & 14 & 12 & 15 & 16 & 14 & 7 & 13 & 9 \\
\end{tabular}
\end{table}

Из этих таблиц видно, что время работы алгоритма растет по мере увеличения как параметра $p_m$, так и параметра $p_c$.
Вместе с тем видно, что и процент неверных ответов падает по мере увеличения тех же параметров.
Очевидно, что необходимо найти некоторые оптимальные значения для того, чтобы процент неверных ответов был невелик и 
одновременно с этим необходимо, чтобы время работы было минимальным. Для того чтобы соединить воедино два этих фактора была введена функция:

\begin{equation}
F(pm, pc) = \alpha\,time(pm, pc) + \beta\,error(pm, pc),
\end{equation} 

которая учитывает время работы и процент ошибок, причем параметр $\alpha$ отвечает за уровень значимости временных затрат, а параметр $\beta$ отвечает за значимость процента ошибок.
Если подставить все полученные данные в эту функцию, то получится результат, который представлен в таблице \ref{tab6}.
\begin{table}[!ht]
\small
\centering
\caption{Значения функции $F$, $\alpha = 0.3$, $\beta = 0.7$,  $|V|$ = 2500 $|E|$ = 90268 $N$ = 20 } \label{tab6}
\begin{tabular}{llllllllllll}
pm/pc & 0.0  & 0.1  & 0.2  & 0.3  & 0.4  & 0.5  & 0.6  & 0.7  & 0.8  & 0.9  & 1.0  \\
0.0 & 0.71 & 0.49 & 0.30 & 0.48 & 0.40 & 0.49 & 0.55 & 0.52 & 0.59 & 0.57 & 0.59  \\
0.1 & 0.45 & 0.36 & 0.22 & 0.31 & 0.35 & 0.37 & 0.32 & 0.36 & 0.28 & 0.42 & 0.35  \\
0.2 & 0.46 & 0.31 & 0.36 & 0.28 & 0.29 & 0.32 & 0.28 & 0.32 & 0.34 & 0.29 & 0.25  \\
0.3 & 0.47 & 0.30 & 0.26 & 0.26 & 0.29 & 0.27 & 0.25 & 0.24 & 0.26 & 0.28 & 0.32  \\
0.4 & 0.38 & 0.35 & 0.29 & 0.33 & 0.22 & 0.26 & 0.31 & 0.27 & 0.30 & 0.41 & 0.30  \\
0.5 & 0.40 & 0.27 & 0.27 & 0.32 & 0.33 & 0.31 & 0.37 & 0.32 & 0.28 & 0.29 & 0.26  \\
0.6 & 0.38 & 0.31 & 0.26 & 0.37 & 0.27 & 0.28 & 0.31 & 0.26 & 0.31 & 0.38 & 0.38  \\
0.7 & 0.45 & 0.34 & 0.38 & 0.34 & 0.34 & 0.30 & 0.36 & 0.33 & 0.40 & 0.33 & 0.30  \\
0.8 & 0.44 & 0.36 & 0.35 & 0.31 & 0.38 & 0.32 & 0.39 & 0.38 & 0.34 & 0.34 & 0.39  \\
0.9 & 0.37 & 0.34 & 0.41 & 0.33 & 0.44 & 0.40 & 0.42 & 0.38 & 0.41 & 0.34 & 0.34  \\
1.0 & 0.47 & 0.35 & 0.32 & 0.36 & 0.35 & 0.39 & 0.40 & 0.37 & 0.30 & 0.38 & 0.38  \\
\end{tabular}
\end{table}


\begin{figure}
\centering
  \begin{tikzpicture}
  \begin{axis}[ 
  	legend pos = south east,
  	no markers,
  	grid = major,
  	xlabel = $pc$,
  	ymin = 0,
  	ymax = 1,
  	xmin = 0,
  	xmax = 1,
  ]
   \legend{
    	$time$,
    	$error$
    };
 \addplot coordinates {
	( 0.0 ,  0.34 )
	( 0.1 ,  0.36 )
	( 0.2 ,  0.43 )
	( 0.3 ,  0.48 )
	( 0.4 ,  0.46 )
	( 0.5 ,  0.42 )
	( 0.6 ,  0.43 )
	( 0.7 ,  0.44 )
	( 0.8 ,  0.47 )
	( 0.9 ,  0.50 )
	( 1.0 ,  0.52 )
 };
 
  \addplot coordinates {
 	( 0.0 ,  0.40 )
 	( 0.1 ,  0.35 )
 	( 0.2 ,  0.23 )
 	( 0.3 ,  0.27 )
 	( 0.4 ,  0.11 )
 	( 0.5 ,  0.20 )
 	( 0.6 ,  0.26 )
 	( 0.7 ,  0.20 )
 	( 0.8 ,  0.22 )
 	( 0.9 ,  0.37 )
 	( 1.0 ,  0.20 )
};
  \end{axis}
  \end{tikzpicture}
  \caption{Нормализованные значения времени выполнения алгоритма и процента ошибок с параметрами $pm = 0.4$, $|V|$ = 2500, $|E|$ = 90268, $N$ = 20} \label{pic8}
\end{figure}

\begin{figure}
\centering
  \begin{tikzpicture}
  \begin{axis}[ 
  	legend pos = south east,
  	no markers,
  	ymin = 0,
  	ymax = 1,
  	xmin = 0,
  	xmax = 1,  	
  	grid = major,
  	xlabel = $pc$,
  	ylabel = $normalized value$,
  ]
   \legend{
    	$time$,
    	$error$
    };
 \addplot coordinates {
	( 0.0 ,  0.40 )
	( 0.1 ,  0.52 )
	( 0.2 ,  0.52 )
	( 0.3 ,  0.64 )
	( 0.4 ,  0.58 )
	( 0.5 ,  0.58 )
	( 0.6 ,  0.59 )
	( 0.7 ,  0.62 )
	( 0.8 ,  0.67 )
	( 0.9 ,  0.69 )
	( 1.0 ,  0.76 )
 };
 
  \addplot coordinates {
	( 0.0 ,  0.37 )
	( 0.1 ,  0.22 )
	( 0.2 ,  0.15 )
	( 0.3 ,  0.26 )
	( 0.4 ,  0.14 )
	( 0.5 ,  0.15 )
	( 0.6 ,  0.19 )
	( 0.7 ,  0.11 )
	( 0.8 ,  0.15 )
	( 0.9 ,  0.25 )
	( 1.0 ,  0.22 )
  };
  \end{axis}
  \end{tikzpicture}
  \caption{Нормализованные значения времени выполнения алгоритма и процента ошибок с параметрами $p_m = 0.6$, $|V|$ = 2500, $|E|$ = 90268, $N$ = 20} \label{pic9}
\end{figure}

\begin{figure}
\centering
	\begin{tikzpicture}
	\begin{axis}
	  [ 
	  	legend pos = south east,
	  	no markers,
	  	grid = major,
	  	xlabel = $N$,
	  	ylabel = $Error (\%)$,
	  	xmax = 50,
	  	xmin = 1,
	  ]
	 \addplot coordinates {
	( 1.0 , 100.0 )
	( 2.0 , 100.0 )
	( 3.0 , 97.0 )
	( 4.0 , 98.0 )
	( 5.0 , 86.0 )
	( 6.0 , 85.0 )
	( 7.0 , 53.0 )
	( 8.0 , 66.0 )
	( 9.0 , 52.0 )
	( 10.0 , 53.0 )
	( 11.0 , 39.0 )
	( 12.0 , 41.0 )
	( 13.0 , 38.0 )
	( 14.0 , 35.0 )
	( 15.0 , 29.0 )
	( 16.0 , 31.0 )
	( 17.0 , 22.0 )
	( 18.0 , 19.0 )
	( 19.0 , 24.0 )
	( 20.0 , 10.0 )
	( 21.0 , 18.0 )
	( 22.0 , 8.0 )
	( 23.0 , 17.0 )
	( 24.0 , 11.0 )
	( 25.0 , 8.0 )
	( 26.0 , 11.0 )
	( 27.0 , 8.0 )
	( 28.0 , 8.0 )
	( 29.0 , 6.0 )
	( 30.0 , 13.0 )
	( 31.0 , 5.0 )
	( 32.0 , 3.0 )
	( 33.0 , 6.0 )
	( 34.0 , 5.0 )
	( 35.0 , 1.0 )
	( 36.0 , 1.0 )
	( 37.0 , 1.0 )
	( 38.0 , 2.0 )
	( 39.0 , 0.0 )
	( 40.0 , 2.0 )
	( 41.0 , 0.0 )
	( 42.0 , 1.0 )
	( 43.0 , 2.0 )
	( 44.0 , 0.0 )
	( 45.0 , 0.0 )
	( 46.0 , 0.0 )
	( 47.0 , 0.0 )
	( 48.0 , 2.0 )
	( 49.0 , 0.0 )
	};
	 \end{axis}
	\end{tikzpicture}
	\caption{Зависимость процента ошибок (\%) от размера популяции $N$, с параметрами $p_m = 0.4$, $p_c = 0.6$} \label{pic10}
\end{figure}




\conclusion
Заключение


\bibliographystyle{gost780uv}
\bibliography{thesis}

\appendix


\end{document}
